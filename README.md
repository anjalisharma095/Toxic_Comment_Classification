# Toxic_Comment_Classification

Dataset: https://drive.google.com/file/d/1xNzvONLQiIFePgXDCFRnnyTnBDaZBEJr/view?usp=sharing

The goal of this project is to create a classifier model that can predict if input text is inappropriate (toxic).
1. Explore the dataset to get a better picture of how the labels are distributed, how they correlate with each
other, and what defines toxic or clean comments.
2. Create a baseline score with a simple logistic regression classifier.
3. Explore the effectiveness of multiple machine learning approaches and select the best for this problem.
4. Select the best model and tune the parameters to maximize performance.
5. Build a the final model with the best performing algorithm and parameters and test it on a holdout subset
of the data. 

BY - ANJALI SHARMA

ROLL NO. - 102015140

SUBGROUP- ENC6
